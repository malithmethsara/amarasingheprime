name: Daily CBSL Rate Update

on:
  schedule:
    - cron: '0 4 * * *' # Runs daily at 9:30 AM Sri Lanka Time
  workflow_dispatch: # Allows manual run button

permissions:
  contents: write

jobs:
  update-rates:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 1. Install Chrome Browser for GitHub Actions
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest

      # 2. Install Selenium (The tool that controls Chrome)
      - name: Install Dependencies
        run: pip install selenium webdriver-manager beautifulsoup4

      - name: Run Scraper with Real Browser
        run: |
          from selenium import webdriver
          from selenium.webdriver.chrome.options import Options
          from selenium.webdriver.chrome.service import Service
          from webdriver_manager.chrome import ChromeDriverManager
          from bs4 import BeautifulSoup
          from datetime import datetime
          import sys
          import time

          # --- SETUP REAL CHROME BROWSER ---
          print("Setting up Chrome...")
          options = Options()
          options.add_argument("--headless") # Run in background (no GUI)
          options.add_argument("--no-sandbox")
          options.add_argument("--disable-dev-shm-usage")
          options.add_argument("--window-size=1920,1080")
          options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

          try:
              driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
              
              # --- LOAD THE PAGE ---
              url = "https://www.cbsl.gov.lk/en/rates-and-indicators/exchange-rates/daily-buy-and-sell-exchange-rates"
              print(f"visiting: {url}")
              driver.get(url)
              
              # WAIT for 5 seconds to let JavaScript load the table
              time.sleep(5) 
              
              # Get the HTML after it has fully loaded
              html = driver.page_source
              soup = BeautifulSoup(html, 'html.parser')
              
              # --- SEARCH FOR DATA ---
              tables = soup.find_all('table')
              print(f"Found {len(tables)} tables on the page.")
              
              jpy_rate = None

              for table in tables:
                  rows = table.find_all('tr')
                  for row in rows:
                      text = row.text.strip().lower()
                      
                      # Look for 'japanese yen' OR 'jpy'
                      if "japanese yen" in text or "jpy" in text:
                          cols = row.find_all('td')
                          # Usually: [Name, Buying, Selling, ...]
                          # We try to grab the 3rd column (Index 2)
                          if len(cols) >= 3:
                              raw_rate = cols[2].text.strip()
                              # Sometimes the rate might be empty or a dash
                              if raw_rate and any(c.isdigit() for c in raw_rate):
                                  jpy_rate = raw_rate
                                  print(f"‚úÖ Found Rate! {text[:15]}... -> Selling: {jpy_rate}")
                                  break
                  if jpy_rate:
                      break
              
              driver.quit()

              # --- SAVE TO FILE ---
              if jpy_rate:
                  # Clean the rate (remove commas/spaces)
                  clean_rate = jpy_rate.replace(',', '').strip()
                  
                  # Validate number
                  try:
                      float(clean_rate)
                  except ValueError:
                      print(f"‚ùå Error: Found value '{clean_rate}' is not a valid number.")
                      sys.exit(1)

                  today = datetime.now().strftime("%Y-%m-%d")
                  new_line = f"{today},{clean_rate}"
                  filename = "CBSL rates.txt" # Filename with space

                  # Avoid duplicates
                  try:
                      with open(filename, "r") as f:
                          content = f.read()
                          if today in content:
                              print("‚ö†Ô∏è Rate for today already exists. Skipping.")
                              sys.exit(0)
                  except FileNotFoundError:
                      pass 

                  # Append
                  with open(filename, "a") as f:
                      f.write(f"\n{new_line}")
                  print(f"‚úÖ Successfully saved: {new_line}")

              else:
                  print("‚ùå Error: Could not find 'Japanese Yen' in any table.")
                  # Debug: Print a bit of the page text to see what we got
                  print("Page Text Snippet:", soup.get_text()[:500])
                  sys.exit(1)

          except Exception as e:
              print(f"‚ùå Critical Error: {e}")
              sys.exit(1)

        shell: python

      - name: Commit and Push
        run: |
          git config --global user.name "Auto-Update Bot"
          git config --global user.email "actions@github.com"
          git add "CBSL rates.txt"
          git diff --quiet && git diff --staged --quiet || (git commit -m "üìà Auto-update CBSL Selling Rate" && git push)
